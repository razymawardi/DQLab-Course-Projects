{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"d - Data Manipulation with Pandas - Part 1 - Handling Missing Values.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNXDnd0cz0j/kdTGCvzL7Ku"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XsRs6v6LvImN"},"source":["# **Handling Missing Values**"]},{"cell_type":"markdown","metadata":{"id":"hiuZQ2gmvYfJ"},"source":["## **Pendahuluan**"]},{"cell_type":"markdown","metadata":{"id":"VdUT5RbcvTec"},"source":["“Aksara, saya barusan kirim email lagi ya berisi link seputar handling missing values untuk Pandas. Kamu bisa belajar lebih lengkap di sana bersama isi modul.”\n","\n"," \n","\n","“Siap!”\n","\n"," \n","\n","Tanpa menunggu lagi, aku mengecek link yang diberikan Andra:\n","\n","https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html"]},{"cell_type":"markdown","metadata":{"id":"LepIPDBjvpkM"},"source":["## **Inspeksi Missing Value**"]},{"cell_type":"markdown","metadata":{"id":"cBqpRGSMvxnJ"},"source":["Value yang hilang/tidak lengkap dari dataframe akan membuat analisis atau model prediksi yang dibuat menjadi tidak akurat dan mengakibatkan keputusan salah yang diambil. Terdapat beberapa cara untuk mengatasi data yang hilang/tidak lengkap tersebut.\n","\n","Data COVID-19 yang akan digunakan ini diambil dari google big query, tetapi sudah disediakan datasetnya dalam format csv dengan nama `\"public data covid19 jhu csse eu.csv\"`. Ini adalah studi kasus untuk meng-handle missing value. Bagaimanakah langkah-langkahnya?\n","\n","Di pandas data yang hilang umumnya direpresentasikan dengan `NaN`.\n","\n","Langkah pertama, kita harus tahu kolom mana yang terdapat data hilang dan berapa banyak dengan cara:\n","\n","**Cara 1:** menerapkan method `.info()` pada dataframe\n","\n","**Cara 2:** mengetahui berapa banyak nilai hilang dari tiap kolom di dataset tersebut dengan menerapkan chaining method pada dataframe yaitu `.isna().sum()`. Method `.isna()` digunakan untuk mengecek berapa data yang bernilai `NaN` dan .sum() menjumlahkannya secara default untuk masing-masing kolom dataframe.\n","\n","\n","\n","\n","**Notes:**\n","\n","Dataset : https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv"]},{"cell_type":"code","metadata":{"id":"0MiykCOhvP8z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1603999316102,"user_tz":-540,"elapsed":3557,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"dbae8a70-8270-4c25-94a3-378e83149fb4"},"source":["import pandas as pd\n","# Baca file \"public data covid19 jhu csse eu.csv\"\n","df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\")\n","\n","# Cetak info dari df\n","print(df.info())\n","\n","# Cetak jumlah missing value di setiap kolom\n","mv = df.isna().sum()\n","print(\"\\nJumlah missing value per kolom:\\n\", mv)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 13 columns):\n"," #   Column          Non-Null Count  Dtype  \n","---  ------          --------------  -----  \n"," 0   province_state  960 non-null    object \n"," 1   country_region  1000 non-null   object \n"," 2   date            1000 non-null   object \n"," 3   latitude        874 non-null    float64\n"," 4   longitude       874 non-null    float64\n"," 5   location_geom   874 non-null    object \n"," 6   confirmed       1000 non-null   int64  \n"," 7   deaths          999 non-null    float64\n"," 8   recovered       999 non-null    float64\n"," 9   active          949 non-null    float64\n"," 10  fips            949 non-null    float64\n"," 11  admin2          842 non-null    object \n"," 12  combined_key    0 non-null      float64\n","dtypes: float64(7), int64(1), object(5)\n","memory usage: 101.7+ KB\n","None\n","\n","Jumlah missing value per kolom:\n"," province_state      40\n","country_region       0\n","date                 0\n","latitude           126\n","longitude          126\n","location_geom      126\n","confirmed            0\n","deaths               1\n","recovered            1\n","active              51\n","fips                51\n","admin2             158\n","combined_key      1000\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yriKae1exQK7"},"source":["## **Treatment untuk Missing Value**"]},{"cell_type":"markdown","metadata":{"id":"3_9CyCq0xihL"},"source":["Terdapat beberapa cara untuk mengatasi missing value, antara lain:\n","\n","- dibiarkan saja,\n","- hapus value itu, atau\n","- isi value tersebut dengan value yang lain (biasanya interpolasi, mean, median, etc)\n"," \n","\n","Sebelum melakukan action ke missing value pada data covid diatas, sebaiknya tampilkan beberapa row teratas dari dataset itu"]},{"cell_type":"code","metadata":{"id":"YR6NnncKxDVH","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1603999316110,"user_tz":-540,"elapsed":3518,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"61d98c21-f6bc-48fe-d403-63d659947831"},"source":["df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>province_state</th>\n","      <th>country_region</th>\n","      <th>date</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>location_geom</th>\n","      <th>confirmed</th>\n","      <th>deaths</th>\n","      <th>recovered</th>\n","      <th>active</th>\n","      <th>fips</th>\n","      <th>admin2</th>\n","      <th>combined_key</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>01-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>18-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>17-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>31-01-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>19-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>22-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>25-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>16-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>27-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>15</td>\n","      <td>0.0</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>NaN</td>\n","      <td>UK</td>\n","      <td>03-02-20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  province_state country_region      date  ...  fips  admin2 combined_key\n","0            NaN             UK  01-02-20  ...   NaN     NaN          NaN\n","1            NaN             UK  18-02-20  ...   NaN     NaN          NaN\n","2            NaN             UK  17-02-20  ...   NaN     NaN          NaN\n","3            NaN             UK  31-01-20  ...   NaN     NaN          NaN\n","4            NaN             UK  19-02-20  ...   NaN     NaN          NaN\n","5            NaN             UK  22-02-20  ...   NaN     NaN          NaN\n","6            NaN             UK  25-02-20  ...   NaN     NaN          NaN\n","7            NaN             UK  16-02-20  ...   NaN     NaN          NaN\n","8            NaN             UK  27-02-20  ...   NaN     NaN          NaN\n","9            NaN             UK  03-02-20  ...   NaN     NaN          NaN\n","\n","[10 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"dkAnNeGqxt0A","colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"status":"ok","timestamp":1603999316116,"user_tz":-540,"elapsed":3504,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"9552111a-a2cf-4576-f3ec-109b549af027"},"source":["df.tail(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>province_state</th>\n","      <th>country_region</th>\n","      <th>date</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>location_geom</th>\n","      <th>confirmed</th>\n","      <th>deaths</th>\n","      <th>recovered</th>\n","      <th>active</th>\n","      <th>fips</th>\n","      <th>admin2</th>\n","      <th>combined_key</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>990</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>15-06-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>34</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>991</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>26-03-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>992</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>09-06-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>24</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>23.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>993</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>21-04-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>15-05-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>7</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>21-05-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>9</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>21-06-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>39.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>26-04-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>26-06-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>45</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>44.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Iowa</td>\n","      <td>US</td>\n","      <td>26-05-20</td>\n","      <td>42.776443</td>\n","      <td>-94.207225</td>\n","      <td>POINT(-94.20722537 42.7764426)</td>\n","      <td>13</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>13.0</td>\n","      <td>19091.0</td>\n","      <td>Humboldt</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    province_state country_region      date  ...     fips    admin2 combined_key\n","990           Iowa             US  15-06-20  ...  19091.0  Humboldt          NaN\n","991           Iowa             US  26-03-20  ...  19091.0  Humboldt          NaN\n","992           Iowa             US  09-06-20  ...  19091.0  Humboldt          NaN\n","993           Iowa             US  21-04-20  ...  19091.0  Humboldt          NaN\n","994           Iowa             US  15-05-20  ...  19091.0  Humboldt          NaN\n","995           Iowa             US  21-05-20  ...  19091.0  Humboldt          NaN\n","996           Iowa             US  21-06-20  ...  19091.0  Humboldt          NaN\n","997           Iowa             US  26-04-20  ...  19091.0  Humboldt          NaN\n","998           Iowa             US  26-06-20  ...  19091.0  Humboldt          NaN\n","999           Iowa             US  26-05-20  ...  19091.0  Humboldt          NaN\n","\n","[10 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"hpbJ-YtJx5DX"},"source":["kemudian lihat kembali jumlah missing value tiap kolomnya agar dapat ditelaah terlebih dahulu."]},{"cell_type":"code","metadata":{"id":"gbxuSSXEyQ7q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1603999316120,"user_tz":-540,"elapsed":3485,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"e28b5f5a-e8f8-4bd7-8db5-264d9a007fed"},"source":["print('jumlah missing values per kolom:\\n',mv)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["jumlah missing values per kolom:\n"," province_state      40\n","country_region       0\n","date                 0\n","latitude           126\n","longitude          126\n","location_geom      126\n","confirmed            0\n","deaths               1\n","recovered            1\n","active              51\n","fips                51\n","admin2             158\n","combined_key      1000\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yDTBaeCkyPF_"},"source":["Hanya kolom combine_key yang keseluruhan barisnya adalah missing value (1000 buah), sementara kolom country_region, date, dan confirmed tidak memiliki missing value. Untuk kolom lainnya terdapat beragam jumlah missing value. Apa yang dapat dilakukan?\n","\n","Untuk memahami mana kolom yang akan ditreatment dengan tiga perlakukan di atas lihat nature dari data terlebih dahulu. Contohnya pada kolom death dan recovered jika ada yang missing value maka kemungkinan terbesarnya adalah tidak ada meninggal atau sembuh pada hari tersebut. \n","\n","Untuk kolom yang seluruhnya missing yaitu combined_key dapat dibuang saja satu kolom itu karena tidak ada data yang dapat diketahui dari kolom tersebut.\n","\n","Sementara, kolom yang lainnya bagaimana? Misal ambil kolom province_stat, missing valuenya dapat terjadi bahwa tidak dilaporkan itu berasal dari daerah mana di negara itu. Dapat mengisi misal dengan string 'unknown' karena tahu kolom tersebut bertipe data string."]},{"cell_type":"markdown","metadata":{"id":"KD5opDJ5yqX0"},"source":["Sekarang dapat menerapkan dua aksi yaitu:\n","- Membiarkannya saja\n","- Mengahapus kolom\n"," \n","\n","Treatment pertama (membiarkannya saja) seperti pada kolom `confirmed, death,` dan `recovered`. Akan tetapi jika tidak ada yang terkonfirmasi, meninggal dan sembuh sebenarnya dapat menukar value ini dengan angka nol. Meskipun ini lebih make sense dalam representasi datanya, tetapi untuk sub bab ini ketiga kolom tersebut diasumsikan dibiarkan memiliki nilai missing value.\n","\n"," \n","\n","Treatment kedua yaitu dengan menghapus kolom, yang mana ini digunakan jika seluruh kolom dari dataset yang dipunyai semua barisnya adalah missing value. Untuk itu dapat menerapkan method `.dropna()` pada dataframe, bagaimana caranya?\n","\n","`nama_dataframe.dropna(axis=1, how=\"all\")`\n","Pada method `.dropna()` ada dua keyword argumen yang harus diisikan yaitu axis dan how. Keyword axis digunakan untuk menentukan arah dataframe yang akan dibuang angka 1 untuk menyatakan kolom (column-based) atau dapat ditulis dalam string \"column\". Jika digunakan angka 0 berarti itu dalam searah index (row-based) atau dapat ditulis dalam string \"index\".\n","\n","Sementara, keyword how digunakan untuk bagaimana cara membuangnya. Opsi yang dapat diterimanya (dalam string) adalah\n","\n"," `\"all\"` artinya jika seluruh data di satu/beberapa kolom atau di satu/beberapa baris adalah missing value.\n","`\"any\"` artinya jika memiliki 1 saja data yang hilang maka buanglah baris/kolom tersebut."]},{"cell_type":"code","metadata":{"id":"mlJZvDLExxw3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1603999316122,"user_tz":-540,"elapsed":3475,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"bbc24323-f8e2-4ebf-c0a3-bf6d4d4a28b6"},"source":["# Cetak ukuran awal dataframe\n","print(\"Ukuran awal df: %d baris, %d kolom.\" % df.shape)\n","\n","# Drop kolom yang seluruhnya missing value dan cetak ukurannya\n","df = df.dropna(axis=1, how=\"all\")\n","print(\"Ukuran df setelah buang kolom dengan seluruh data missing: %d baris, %d kolom.\" % df.shape)\n","\n","# Drop baris jika ada satu saja data yang missing dan cetak ukurannya\n","df = df.dropna(axis=0, how=\"any\")\n","print(\"Ukuran df setelah dibuang baris yang memiliki sekurangnya 1 missing value: %d baris, %d kolom.\" % df.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Ukuran awal df: 1000 baris, 13 kolom.\n","Ukuran df setelah buang kolom dengan seluruh data missing: 1000 baris, 12 kolom.\n","Ukuran df setelah dibuang baris yang memiliki sekurangnya 1 missing value: 746 baris, 12 kolom.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"G0Cuzqs6z_f8"},"source":["Sekarang, kita akan melakukan treatment ketiga untuk menghandle missing value pada dataframe. Treatment ini dilakukan dengan cara mengisi missing value dengan nilai lain, yang dapat berupa :\n","\n","- nilai statistik seperti mean atau median\n","- interpolasi data\n","- text tertentu\n"," \n","\n","Kita akan mulai pada kolom yang missing yang tipe datanya adalah berupa object. Kolom tersebut adalah `province_state`, karena tidak tahu secara persis province_state mana yang dimaksud, bisa menempatkan string `\"unknown\"` sebagai substitusi missing value. Meskipun keduanya berarti sama-sama tidak tahu tetapi berbeda dalam representasi datanya.\n","\n","Untuk melakukan hal demikian dapat menggunakan method `.fillna()` pada kolom dataframe yang dimaksud."]},{"cell_type":"code","metadata":{"id":"7CABH6bKzb05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1603999598500,"user_tz":-540,"elapsed":2881,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"e864443e-1fa0-4ec2-a2da-134cb0a20c7c"},"source":["# Baca file \"public data covid19 jhu csse eu.csv\"\n","df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\")\n","\n","# Cetak unique value pada kolom province_state\n","print(\"Unique value awal:\\n\", df[\"province_state\"].unique())\n","\n","# Ganti missing value dengan string \"unknown_province_state\"\n","df[\"province_state\"] = df[\"province_state\"].fillna(\"unknown\")\n","\n","# Cetak kembali unique value pada kolom province_state\n","print(\"Unique value setelah fillna:\\n\", df[\"province_state\"].unique())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Unique value awal:\n"," [nan 'US' 'Guam' 'Iowa']\n","Unique value setelah fillna:\n"," ['unknown' 'US' 'Guam' 'Iowa']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yPDWEjLV1ASg"},"source":["Terlihat bahwa unique value di kolom \"province_state\" yang semula ada `nan` telah berubah menjadi `\"unknown\"`. "]},{"cell_type":"markdown","metadata":{"id":"YmBQmm7m1TG3"},"source":["Masih melanjutkan bagaimana meng-handle missing value tentunya dengan jalan mengganti missing value dengan nilai lainnya. Sebelumnya kita telah mengganti kolom bertipe objek dengan sesuatu string/teks.\n","\n","Sekarang kita akan mengganti missing value dengan nilai statistik kolom bersangkutan, baik median atau mean (nilai rata-rata). Misalnya akan menggunakan kolom **active**. Dengan mengabaikan terlebih dahulu sebaran berdasarkan negara (univariate), jika mengisi dengan nilai rata-rata maka harus melihat terlebih dahulu data apakah memiliki ouliers atau tidak. Jika ada outliers dari data maka menggunakan nilai tengah (median) data adalah cara yang lebih safe.\n","\n","Untuk itu diputuskan dengan mengecek nilai median dan nilai mean kolom active juga nilai min dan max-nya. Jika data pada kolom active terdistribusi normal maka nilai mean dan median akan hampir sama."]},{"cell_type":"code","metadata":{"id":"3hptWVA40mUp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604000150564,"user_tz":-540,"elapsed":1253,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"6656be45-cda9-4c64-82b1-793e35ddcf40"},"source":["# cek mean, median, max dan min dari kolom active\n","print('Min     : %.2f' % df.active.min())\n","print('Mean    : %.2f' % df.active.mean())\n","print('Median  : %.2f' % df.active.median())\n","print('Max     : %.2f' % df.active.max())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Min     : -6.00\n","Mean    : 192.57\n","Median  : 41.00\n","Max     : 2243.00\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nUCtLVWV3DOK"},"source":["Terlihat data memiliki distribusi yang skewness, karena nilai mean dan median yang cukup jauh serta range data yang cukup lebar. Di sini pada kolom active data memiliki outliers. Jadi kita akan mengisi missing value dengan median."]},{"cell_type":"code","metadata":{"id":"f7wHYYUN2WW1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604000253580,"user_tz":-540,"elapsed":4043,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"0020de79-8d29-45a4-8380-2f59f4e5bfbd"},"source":["# Baca file \"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\"\n","df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\")\n","\n","# Cetak nilai mean dan median awal \n","print(\"Awal: mean = %f, median = %f.\" % (df[\"active\"].mean(), df[\"active\"].median()))\n","\n","# Isi missing value kolom active dengan median\n","df_median = df[\"active\"].fillna(df[\"active\"].median())\n","\n","# Cetak nilai mean dan median awal setelah diisi dengan median\n","print(\"Fillna median: mean = %f, median = %f.\" % (df_median.mean(), df_median.median()))\n","\n","# Isi missing value kolom active dengan mean\n","df_mean = df[\"active\"].fillna(df[\"active\"].mean())\n","\n","# Cetak nilai mean dan median awal setelah diisi dengan mean\n","print(\"Fillna mean: mean = %f, median = %f.\" % (df_mean.mean(), df_mean.median()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Awal: mean = 192.571128, median = 41.000000.\n","Fillna median: mean = 184.841000, median = 41.000000.\n","Fillna mean: mean = 192.571128, median = 49.000000.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Iu_Y8ZJM4HAB"},"source":["### Interpolasi"]},{"cell_type":"markdown","metadata":{"id":"hbnmGx7f3l-K"},"source":["Selanjutnya, kita akan menggunakan teknik interpolasi dalam mengisi nilai missing value pada suatu dataset.\n","\n","Data yang menggunakan interpolasi untuk mengisi data yang hilang adalah time series data, yang secara default akan diisi dengan interpolasi linear."]},{"cell_type":"code","metadata":{"id":"i6Y-Huby3RCi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604000358887,"user_tz":-540,"elapsed":1353,"user":{"displayName":"razy mawardi","photoUrl":"","userId":"09382810520223821882"}},"outputId":"210d54d9-fbd2-42ed-aae2-b6cdb8fc4517"},"source":["import numpy as np\n","\n","# Data\n","ts = pd.Series({\n","   \"2020-01-01\":9,\n","   \"2020-01-02\":np.nan,\n","   \"2020-01-05\":np.nan,\n","   \"2020-01-07\":24,\n","   \"2020-01-10\":np.nan,\n","   \"2020-01-12\":np.nan,\n","   \"2020-01-15\":33,\n","   \"2020-01-17\":np.nan,\n","   \"2020-01-16\":40,\n","   \"2020-01-20\":45,\n","   \"2020-01-22\":52,\n","   \"2020-01-25\":75,\n","   \"2020-01-28\":np.nan,\n","   \"2020-01-30\":np.nan\n","})\n","\n","# Isi missing value menggunakan interpolasi linier\n","ts = ts.interpolate()\n","\n","# Cetak time series setelah interpolasi linier\n","print(\"Setelah diisi missing valuenya:\\n\", ts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Setelah diisi missing valuenya:\n"," 2020-01-01     9.0\n","2020-01-02    14.0\n","2020-01-05    19.0\n","2020-01-07    24.0\n","2020-01-10    27.0\n","2020-01-12    30.0\n","2020-01-15    33.0\n","2020-01-17    36.5\n","2020-01-16    40.0\n","2020-01-20    45.0\n","2020-01-22    52.0\n","2020-01-25    75.0\n","2020-01-28    75.0\n","2020-01-30    75.0\n","dtype: float64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mPAvWkTQ3xwA"},"source":[""],"execution_count":null,"outputs":[]}]}